{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "40823733",
      "metadata": {
        "id": "40823733"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array,array_to_img\n",
        "import cv2\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "from tensorflow.keras.losses import categorical_crossentropy,mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "079db12d",
      "metadata": {
        "id": "079db12d"
      },
      "outputs": [],
      "source": [
        "class Yolo_Reshape(tf.keras.layers.Layer):\n",
        "    def __init__(self, target_shape):\n",
        "        super(Yolo_Reshape, self).__init__()\n",
        "        self.target_shape = tuple(target_shape)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'target_shape': self.target_shape\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def call(self, input):\n",
        "        # grids 7x7\n",
        "        S = [self.target_shape[0], self.target_shape[1]]\n",
        "        # classes\n",
        "        C = 4\n",
        "        # no of bounding boxes per grid\n",
        "        B = 2\n",
        "\n",
        "        idx1 = S[0] * S[1] * C \n",
        "        idx2 = idx1 + S[0] * S[1] * B \n",
        "\n",
        "        # class probabilities\n",
        "        class_probs = K.reshape(input[:, :idx1], (K.shape(input)[0],) + tuple([S[0], S[1], C]))\n",
        "        class_probs = K.softmax(class_probs)\n",
        "\n",
        "        #confidence\n",
        "        confs = K.reshape(input[:, idx1:idx2], (K.shape(input)[0],) + tuple([S[0], S[1], B]))\n",
        "        confs = K.sigmoid(confs)\n",
        "\n",
        "        # boxes\n",
        "        boxes = K.reshape(input[:, idx2:], (K.shape(input)[0],) + tuple([S[0], S[1], B * 4]))\n",
        "        boxes = K.sigmoid(boxes)\n",
        "\n",
        "        outputs = K.concatenate([class_probs, confs, boxes])\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86d4f1fe",
      "metadata": {
        "id": "86d4f1fe"
      },
      "source": [
        "### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb9af1a",
      "metadata": {
        "id": "abb9af1a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def xywh2minmax(xy, wh):\n",
        "    xy_min = xy - wh / 2\n",
        "    xy_max = xy + wh / 2\n",
        "\n",
        "    return xy_min, xy_max\n",
        "\n",
        "\n",
        "def iou(pred_mins, pred_maxes, true_mins, true_maxes):\n",
        "    intersect_mins = K.maximum(pred_mins, true_mins)\n",
        "    intersect_maxes = K.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\n",
        "    pred_wh = pred_maxes - pred_mins\n",
        "    true_wh = true_maxes - true_mins\n",
        "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores = intersect_areas / union_areas\n",
        "\n",
        "    return iou_scores\n",
        "\n",
        "\n",
        "def yolo_head(feats):\n",
        "    # Dynamic implementation of conv dims for fully convolutional model.\n",
        "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
        "    # In YOLO the height index is the inner most iteration.\n",
        "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
        "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
        "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
        "\n",
        "    # TODO: Repeat_elements and tf.split doesn't support dynamic splits.\n",
        "    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n",
        "    conv_width_index = K.tile(\n",
        "        K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
        "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
        "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
        "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
        "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
        "\n",
        "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
        "\n",
        "    box_xy = (feats[..., :2] + conv_index) / conv_dims * 448\n",
        "    box_wh = feats[..., 2:4] * 448\n",
        "\n",
        "    return box_xy, box_wh\n",
        "\n",
        "\n",
        "def yolo_loss(y_true, y_pred):\n",
        "    label_class = y_true[..., :4]  \n",
        "    label_box = y_true[..., 5:9]  \n",
        "    response_mask = y_true[..., 4]  \n",
        "    response_mask = K.expand_dims(response_mask)  \n",
        "\n",
        "    predict_class = y_pred[..., :4]  \n",
        "    predict_trust = y_pred[..., 4:6]  \n",
        "    predict_box = y_pred[..., 6:]  \n",
        "\n",
        "    _label_box = K.reshape(label_box, [-1, 7, 7, 1, 4])\n",
        "    _predict_box = K.reshape(predict_box, [-1, 7, 7, 2, 4])\n",
        "\n",
        "    label_xy, label_wh = yolo_head(_label_box)  \n",
        "    label_xy = K.expand_dims(label_xy, 3)  \n",
        "    label_wh = K.expand_dims(label_wh, 3)  \n",
        "    label_xy_min, label_xy_max = xywh2minmax(label_xy, label_wh)  \n",
        "\n",
        "    predict_xy, predict_wh = yolo_head(_predict_box)  \n",
        "    predict_xy = K.expand_dims(predict_xy, 4)  \n",
        "    predict_wh = K.expand_dims(predict_wh, 4)  \n",
        "    predict_xy_min, predict_xy_max = xywh2minmax(predict_xy, predict_wh)  \n",
        "\n",
        "    iou_scores = iou(predict_xy_min, predict_xy_max, label_xy_min, label_xy_max)  \n",
        "    best_ious = K.max(iou_scores, axis=4) \n",
        "    best_box = K.max(best_ious, axis=3, keepdims=True)  \n",
        "\n",
        "    box_mask = K.cast(best_ious >= best_box, K.dtype(best_ious))  \n",
        "\n",
        "    no_object_loss = 0.5 * (1 - box_mask * response_mask) * K.square(0 - predict_trust)\n",
        "    object_loss = box_mask * response_mask * K.square(1 - predict_trust)\n",
        "    confidence_loss = no_object_loss + object_loss\n",
        "    confidence_loss = K.sum(confidence_loss)\n",
        "\n",
        "    class_loss = response_mask * K.square(label_class - predict_class)\n",
        "    class_loss = K.sum(class_loss)\n",
        "\n",
        "    _label_box = K.reshape(label_box, [-1, 7, 7, 1, 4])\n",
        "    _predict_box = K.reshape(predict_box, [-1, 7, 7, 2, 4])\n",
        "\n",
        "    label_xy, label_wh = yolo_head(_label_box)  \n",
        "    predict_xy, predict_wh = yolo_head(_predict_box) \n",
        "\n",
        "    box_mask = K.expand_dims(box_mask)\n",
        "    response_mask = K.expand_dims(response_mask)\n",
        "\n",
        "    box_loss = 5 * box_mask * response_mask * K.square((label_xy - predict_xy) / 448)\n",
        "    box_loss += 5 * box_mask * response_mask * K.square((K.sqrt(label_wh) - K.sqrt(predict_wh)) / 448)\n",
        "    box_loss = K.sum(box_loss)\n",
        "\n",
        "    loss = confidence_loss + class_loss + box_loss\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Architecture"
      ],
      "metadata": {
        "id": "QuIvjZN-GnbZ"
      },
      "id": "QuIvjZN-GnbZ"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "248af0ae",
      "metadata": {
        "id": "248af0ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dfcfb30-2acc-4de0-dd44-3a4ebe69b75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n",
            "80150528/80134624 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "input_height = 448\n",
        "input_width = 448\n",
        "cell_size = 7\n",
        "num_classes = 4\n",
        "boxes_per_cell =2\n",
        "\n",
        "base_model = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape=(input_height, input_width, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    base_model.trainable = False\n",
        "\n",
        "#for layer in base_model.layers[-2:]:\n",
        "#    print(layer)\n",
        "#    base_model.trainable = True\n",
        "\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "# x = tf.keras.layers.Dense(256)(x)\n",
        "x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(7*7*14, activation='sigmoid')(x)\n",
        "output = Yolo_Reshape((7,7,14))(x)\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e92c90e",
      "metadata": {
        "id": "6e92c90e"
      },
      "source": [
        "### Label Tensor Processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVffK10wPlui",
        "outputId": "0e285bc5-e499-4594-8f0d-577840a5cd10"
      },
      "id": "rVffK10wPlui",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 448, 448, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 448, 448, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 448, 448, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 224, 224, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 224, 224, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 224, 224, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 112, 112, 128)     0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 112, 112, 256)     295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 112, 112, 256)     590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 112, 112, 256)     590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 112, 112, 256)     590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 56, 56, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 56, 56, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 56, 56, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 686)               351918    \n",
            "                                                                 \n",
            " yolo__reshape (Yolo_Reshape  (None, 7, 7, 14)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,638,958\n",
            "Trainable params: 614,574\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pipeline"
      ],
      "metadata": {
        "id": "o5b4lAU-h4vy"
      },
      "id": "o5b4lAU-h4vy"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/dataset/train_files.pkl','rb') as f:\n",
        "    train_file = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/dataset/test_files.pkl','rb') as f:\n",
        "    test_file = pickle.load(f)\n",
        "\n",
        "image_path = '/content/drive/MyDrive/dataset/images/'\n",
        "label_path = '/content/drive/MyDrive/dataset/labels/'\n",
        "S = 7\n",
        "C = 4\n",
        "B = 2\n",
        "\n",
        "def load_data(files):\n",
        "  x = []\n",
        "  y = []\n",
        "  for file in tqdm(files,total=len(files)):\n",
        "    label_file_path = label_path+file+'.txt'\n",
        "    image_file_path = image_path+file+'.jpg'\n",
        "    try:\n",
        "      label_f = open(label_file_path,'r',encoding='utf-8')\n",
        "      image = load_img(image_file_path,target_size=(input_height,input_width))\n",
        "    except FileNotFoundError:\n",
        "      print('no file')\n",
        "      continue\n",
        "    x.append(image_file_path)\n",
        "    y.append(label_file_path)\n",
        "  return x,y\n",
        "\n",
        "def read_image(path):\n",
        "  x = load_img(path,target_size=(input_height,input_width))\n",
        "  x = img_to_array(x)\n",
        "  x = x/255\n",
        "  return x\n",
        "\n",
        "def get_boxes(label_file):\n",
        "    boxes = []\n",
        "    for box in label_file.readlines():\n",
        "        cls,x,y,w,h = box.split(' ')\n",
        "        cls = int(cls)\n",
        "        x,y = float(x),float(y)\n",
        "        w,h = float(w),float(h)\n",
        "        boxes.append([cls,x,y,w,h])\n",
        "    return boxes\n",
        "\n",
        "def read_label(path):\n",
        "    label_file = open(path,'r',encoding='utf-8')\n",
        "    \n",
        "    boxes = get_boxes(label_file)\n",
        "    label_matrix = np.zeros((S, S, C + 5 * B))\n",
        "        \n",
        "    for c,x,y,w,h in boxes:\n",
        "        \n",
        "      i, j = int(S * y), int(S * x)\n",
        "      x_cell, y_cell = S * x - j, S * y - i\n",
        "      width_cell, height_cell = w * S, h * S\n",
        "\n",
        "      if label_matrix[i, j, 4] == 0:\n",
        "        # Set that there exists an object\n",
        "        label_matrix[i, j, 4] = 1\n",
        "        label_matrix[i, j, 5] = 1\n",
        "                \n",
        "        # Box coordinates\n",
        "        label_matrix[i, j, 6:10] = x_cell,y_cell,w,h   #x,y,w,h\n",
        "        label_matrix[i, j, 10:] = x_cell,y_cell,w,h   #x,y,w,h\n",
        "        # Set one hot encoding for class_label\n",
        "        label_matrix[i, j, c] = 1\n",
        "\n",
        "    return label_matrix\n",
        "\n",
        "def preprocess(x, y):\n",
        "  def f(x, y):\n",
        "    x = x.decode()\n",
        "    y = y.decode()\n",
        "\n",
        "    x = read_image(x)\n",
        "    y = read_label(y)\n",
        "\n",
        "    return x, y.astype('float64')\n",
        "\n",
        "  images, masks = tf.numpy_function(f, [x, y], [tf.float32, tf.float64])\n",
        "  \n",
        "  images.set_shape([448, 448, 3])\n",
        "  masks.set_shape([7, 7, 14])\n",
        "\n",
        "  return images, masks\n",
        "\n",
        "def tf_dataset(x, y, batch=70):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "  dataset = dataset.map(preprocess)\n",
        "  dataset = dataset.batch(batch)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "uK4QtdAnh04j"
      },
      "id": "uK4QtdAnh04j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images, val_masks = load_data(test_file[:30])\n",
        "val_dataset = tf_dataset(val_images, val_masks)\n",
        "\n",
        "train_images, train_masks = load_data(train_file[100:250])\n",
        "train_dataset = tf_dataset(train_images, train_masks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zyE6Gp6_P1j",
        "outputId": "b493335c-ab0a-43f8-8515-4bb38763553d"
      },
      "id": "6zyE6Gp6_P1j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 98.54it/s]\n",
            "100%|██████████| 150/150 [00:38<00:00,  3.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "OkhTbSahHmqN"
      },
      "id": "OkhTbSahHmqN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066bc02a",
      "metadata": {
        "id": "066bc02a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d5e03e-28ef-4a19-baed-4ecb689fcc5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "46/46 [==============================] - 1594s 35s/step - loss: 1076.9155 - val_loss: 1022.3558\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 44s 947ms/step - loss: 1062.3478 - val_loss: 1021.6894\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 44s 948ms/step - loss: 1062.1815 - val_loss: 1021.5899\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 44s 950ms/step - loss: 1062.0823 - val_loss: 1021.5048\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 43s 929ms/step - loss: 1062.0596 - val_loss: 1021.4048\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 44s 946ms/step - loss: 1062.0577 - val_loss: 1021.3903\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 42s 910ms/step - loss: 1062.0771 - val_loss: 1021.3231\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 42s 909ms/step - loss: 1062.0649 - val_loss: 1021.7278\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 42s 908ms/step - loss: 1062.0199 - val_loss: 1021.4273\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 42s 906ms/step - loss: 1061.8920 - val_loss: 1021.5016\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 42s 904ms/step - loss: 1061.8688 - val_loss: 1021.4886\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 42s 895ms/step - loss: 1061.8718 - val_loss: 1021.4736\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 42s 903ms/step - loss: 1061.8405 - val_loss: 1021.5054\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 43s 913ms/step - loss: 1061.7927 - val_loss: 1021.4188\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 43s 917ms/step - loss: 1061.8695 - val_loss: 1021.7283\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 43s 922ms/step - loss: 1061.7410 - val_loss: 1021.4328\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 43s 916ms/step - loss: 1061.9281 - val_loss: 1021.4694\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 43s 915ms/step - loss: 1061.9753 - val_loss: 1021.7272\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 42s 910ms/step - loss: 1061.8231 - val_loss: 1021.9357\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 42s 909ms/step - loss: 1061.6414 - val_loss: 1021.5770\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 43s 912ms/step - loss: 1061.7734 - val_loss: 1021.5588\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 43s 928ms/step - loss: 1061.6580 - val_loss: 1021.6566\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 43s 927ms/step - loss: 1061.7273 - val_loss: 1021.1791\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 43s 913ms/step - loss: 1061.5067 - val_loss: 1021.2872\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 43s 917ms/step - loss: 1061.4307 - val_loss: 1021.3745\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 43s 917ms/step - loss: 1061.3712 - val_loss: 1021.1680\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 44s 934ms/step - loss: 1061.2355 - val_loss: 1021.1873\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 43s 917ms/step - loss: 1061.1146 - val_loss: 1021.5797\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 42s 905ms/step - loss: 1060.9670 - val_loss: 1021.3842\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 43s 926ms/step - loss: 1060.7500 - val_loss: 1020.9655\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 43s 925ms/step - loss: 1060.5781 - val_loss: 1020.3900\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 43s 924ms/step - loss: 1060.4031 - val_loss: 1020.3362\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 43s 925ms/step - loss: 1060.0233 - val_loss: 1019.9106\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 44s 934ms/step - loss: 1059.6179 - val_loss: 1019.6355\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 44s 939ms/step - loss: 1059.3760 - val_loss: 1019.4546\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 44s 934ms/step - loss: 1059.0000 - val_loss: 1019.1023\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 44s 940ms/step - loss: 1058.8331 - val_loss: 1018.9536\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 43s 919ms/step - loss: 1058.5446 - val_loss: 1018.7107\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 44s 946ms/step - loss: 1058.0660 - val_loss: 1018.3771\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 44s 935ms/step - loss: 1057.7157 - val_loss: 1018.2835\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 44s 936ms/step - loss: 1057.3995 - val_loss: 1018.1885\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 44s 949ms/step - loss: 1057.0964 - val_loss: 1018.1002\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 44s 942ms/step - loss: 1056.8186 - val_loss: 1018.0198\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 44s 943ms/step - loss: 1056.5892 - val_loss: 1017.9256\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 44s 939ms/step - loss: 1056.3817 - val_loss: 1017.7672\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 44s 943ms/step - loss: 1056.2006 - val_loss: 1017.7869\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 44s 940ms/step - loss: 1056.0112 - val_loss: 1017.6700\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 45s 956ms/step - loss: 1055.8319 - val_loss: 1017.5334\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 44s 947ms/step - loss: 1055.6759 - val_loss: 1017.3800\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 44s 948ms/step - loss: 1055.5205 - val_loss: 1017.2954\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 45s 960ms/step - loss: 1055.3571 - val_loss: 1017.1580\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 44s 951ms/step - loss: 1055.2261 - val_loss: 1017.0850\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 44s 950ms/step - loss: 1055.1056 - val_loss: 1016.9090\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 43s 921ms/step - loss: 1054.9828 - val_loss: 1016.6810\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 43s 914ms/step - loss: 1054.8735 - val_loss: 1016.5929\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 43s 920ms/step - loss: 1054.7856 - val_loss: 1016.5285\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 43s 920ms/step - loss: 1054.6956 - val_loss: 1016.4703\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 44s 938ms/step - loss: 1054.6315 - val_loss: 1016.4199\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 43s 919ms/step - loss: 1054.5275 - val_loss: 1016.3666\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 44s 937ms/step - loss: 1054.4406 - val_loss: 1016.3167\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 44s 934ms/step - loss: 1054.3020 - val_loss: 1016.2598\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 44s 942ms/step - loss: 1054.1562 - val_loss: 1016.2125\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 44s 944ms/step - loss: 1054.0227 - val_loss: 1016.1617\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 44s 953ms/step - loss: 1053.8995 - val_loss: 1016.0656\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 44s 935ms/step - loss: 1053.8156 - val_loss: 1015.9568\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 44s 947ms/step - loss: 1053.7119 - val_loss: 1015.8328\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 44s 951ms/step - loss: 1053.5615 - val_loss: 1015.6848\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 44s 945ms/step - loss: 1053.3275 - val_loss: 1015.4757\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 44s 946ms/step - loss: 1052.9991 - val_loss: 1015.2906\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 44s 946ms/step - loss: 1052.7068 - val_loss: 1015.2280\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 43s 931ms/step - loss: 1052.4745 - val_loss: 1015.1703\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 45s 958ms/step - loss: 1052.2798 - val_loss: 1015.1258\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 44s 947ms/step - loss: 1052.1270 - val_loss: 1015.1005\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 44s 949ms/step - loss: 1052.0043 - val_loss: 1015.0770\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 45s 955ms/step - loss: 1051.8933 - val_loss: 1015.0465\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 44s 938ms/step - loss: 1051.7893 - val_loss: 1015.0140\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 44s 945ms/step - loss: 1051.6919 - val_loss: 1014.9908\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 44s 943ms/step - loss: 1051.6135 - val_loss: 1014.9572\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 44s 949ms/step - loss: 1051.5424 - val_loss: 1014.9216\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 44s 947ms/step - loss: 1051.4592 - val_loss: 1014.8803\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 44s 943ms/step - loss: 1051.3784 - val_loss: 1014.8360\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 44s 935ms/step - loss: 1051.3002 - val_loss: 1014.7928\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 44s 943ms/step - loss: 1051.2222 - val_loss: 1014.7519\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 43s 925ms/step - loss: 1051.1345 - val_loss: 1014.7142\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 43s 930ms/step - loss: 1051.0383 - val_loss: 1014.6920\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 44s 946ms/step - loss: 1050.9218 - val_loss: 1014.6906\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 44s 942ms/step - loss: 1050.7953 - val_loss: 1014.6596\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 44s 933ms/step - loss: 1050.6917 - val_loss: 1014.6150\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 45s 956ms/step - loss: 1050.6030 - val_loss: 1014.5702\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 44s 939ms/step - loss: 1050.4872 - val_loss: 1014.5178\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 43s 926ms/step - loss: 1050.4062 - val_loss: 1014.4800\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 44s 946ms/step - loss: 1050.3329 - val_loss: 1014.4446\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 45s 955ms/step - loss: 1050.2682 - val_loss: 1014.4187\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 44s 942ms/step - loss: 1050.2079 - val_loss: 1014.3964\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 45s 959ms/step - loss: 1050.1464 - val_loss: 1014.3707\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 45s 961ms/step - loss: 1050.1002 - val_loss: 1014.3499\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 44s 944ms/step - loss: 1050.0533 - val_loss: 1014.3343\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 44s 937ms/step - loss: 1050.0060 - val_loss: 1014.3140\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 43s 912ms/step - loss: 1049.9525 - val_loss: 1014.3006\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 43s 928ms/step - loss: 1049.8828 - val_loss: 1014.2912\n"
          ]
        }
      ],
      "source": [
        "# filepath = os.path.join('drive','MyDrive','yolo_checkpoint.h5')\n",
        "# checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     filepath,\n",
        "#     save_weights_only=True,\n",
        "#     save_freq=\"epoch\",\n",
        "# )\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss=yolo_loss,optimizer = optimizer)\n",
        "H = model.fit((train_dataset),batch_size=100,epochs=100,validation_data = (val_dataset))\n",
        "model.save_weights('/content/drive/MyDrive/Deep Sort/yoloweights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss=yolo_loss,optimizer = 'adam')\n",
        "H = model.fit((train_dataset),batch_size=5,epochs=101,validation_data = (val_dataset))\n",
        "model.save_weights('/content/drive/MyDrive/yoloweights2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esYOYHWz_Z4l",
        "outputId": "30ba61c2-7a90-4178-a3fe-420ca48f570a"
      },
      "id": "esYOYHWz_Z4l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/101\n",
            "3/3 [==============================] - 42s 11s/step - loss: 1057.0985 - val_loss: 481.4908\n",
            "Epoch 2/101\n",
            "3/3 [==============================] - 3s 895ms/step - loss: 1052.8456 - val_loss: 480.6438\n",
            "Epoch 3/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1051.3143 - val_loss: 480.4181\n",
            "Epoch 4/101\n",
            "3/3 [==============================] - 3s 796ms/step - loss: 1050.1294 - val_loss: 480.5977\n",
            "Epoch 5/101\n",
            "3/3 [==============================] - 3s 796ms/step - loss: 1049.1694 - val_loss: 480.8477\n",
            "Epoch 6/101\n",
            "3/3 [==============================] - 3s 797ms/step - loss: 1048.4906 - val_loss: 480.8048\n",
            "Epoch 7/101\n",
            "3/3 [==============================] - 3s 803ms/step - loss: 1047.7189 - val_loss: 480.7544\n",
            "Epoch 8/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1047.2035 - val_loss: 480.7532\n",
            "Epoch 9/101\n",
            "3/3 [==============================] - 3s 793ms/step - loss: 1046.6423 - val_loss: 480.6631\n",
            "Epoch 10/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1045.5642 - val_loss: 480.4124\n",
            "Epoch 11/101\n",
            "3/3 [==============================] - 3s 798ms/step - loss: 1044.0762 - val_loss: 480.2740\n",
            "Epoch 12/101\n",
            "3/3 [==============================] - 3s 804ms/step - loss: 1042.6250 - val_loss: 480.2471\n",
            "Epoch 13/101\n",
            "3/3 [==============================] - 3s 803ms/step - loss: 1041.4126 - val_loss: 480.1307\n",
            "Epoch 14/101\n",
            "3/3 [==============================] - 3s 804ms/step - loss: 1040.1139 - val_loss: 480.2479\n",
            "Epoch 15/101\n",
            "3/3 [==============================] - 3s 810ms/step - loss: 1038.8527 - val_loss: 480.6188\n",
            "Epoch 16/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1038.0067 - val_loss: 480.9440\n",
            "Epoch 17/101\n",
            "3/3 [==============================] - 3s 826ms/step - loss: 1037.3842 - val_loss: 481.1912\n",
            "Epoch 18/101\n",
            "3/3 [==============================] - 3s 817ms/step - loss: 1036.9257 - val_loss: 481.3141\n",
            "Epoch 19/101\n",
            "3/3 [==============================] - 3s 797ms/step - loss: 1036.5490 - val_loss: 481.3539\n",
            "Epoch 20/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1036.1492 - val_loss: 481.2086\n",
            "Epoch 21/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1035.6736 - val_loss: 480.9038\n",
            "Epoch 22/101\n",
            "3/3 [==============================] - 3s 805ms/step - loss: 1035.2024 - val_loss: 480.6946\n",
            "Epoch 23/101\n",
            "3/3 [==============================] - 3s 805ms/step - loss: 1034.7457 - val_loss: 480.6364\n",
            "Epoch 24/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1034.2531 - val_loss: 480.5287\n",
            "Epoch 25/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1033.7128 - val_loss: 480.2157\n",
            "Epoch 26/101\n",
            "3/3 [==============================] - 3s 808ms/step - loss: 1033.1382 - val_loss: 479.8120\n",
            "Epoch 27/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1032.5613 - val_loss: 479.4684\n",
            "Epoch 28/101\n",
            "3/3 [==============================] - 3s 806ms/step - loss: 1032.0092 - val_loss: 479.2529\n",
            "Epoch 29/101\n",
            "3/3 [==============================] - 3s 807ms/step - loss: 1031.4783 - val_loss: 479.1491\n",
            "Epoch 30/101\n",
            "3/3 [==============================] - 3s 811ms/step - loss: 1030.8889 - val_loss: 479.0469\n",
            "Epoch 31/101\n",
            "3/3 [==============================] - 3s 806ms/step - loss: 1030.2924 - val_loss: 478.9085\n",
            "Epoch 32/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1029.7831 - val_loss: 478.7319\n",
            "Epoch 33/101\n",
            "3/3 [==============================] - 3s 802ms/step - loss: 1029.1929 - val_loss: 478.6003\n",
            "Epoch 34/101\n",
            "3/3 [==============================] - 3s 802ms/step - loss: 1028.5956 - val_loss: 478.5700\n",
            "Epoch 35/101\n",
            "3/3 [==============================] - 3s 804ms/step - loss: 1028.0536 - val_loss: 478.5519\n",
            "Epoch 36/101\n",
            "3/3 [==============================] - 3s 806ms/step - loss: 1027.5542 - val_loss: 478.3693\n",
            "Epoch 37/101\n",
            "3/3 [==============================] - 3s 805ms/step - loss: 1027.0316 - val_loss: 478.0765\n",
            "Epoch 38/101\n",
            "3/3 [==============================] - 3s 808ms/step - loss: 1026.4965 - val_loss: 477.8230\n",
            "Epoch 39/101\n",
            "3/3 [==============================] - 3s 807ms/step - loss: 1025.9719 - val_loss: 477.6740\n",
            "Epoch 40/101\n",
            "3/3 [==============================] - 3s 809ms/step - loss: 1025.4933 - val_loss: 477.6211\n",
            "Epoch 41/101\n",
            "3/3 [==============================] - 3s 831ms/step - loss: 1025.0315 - val_loss: 477.6254\n",
            "Epoch 42/101\n",
            "3/3 [==============================] - 3s 812ms/step - loss: 1024.5493 - val_loss: 477.6383\n",
            "Epoch 43/101\n",
            "3/3 [==============================] - 3s 809ms/step - loss: 1024.0599 - val_loss: 477.6389\n",
            "Epoch 44/101\n",
            "3/3 [==============================] - 3s 802ms/step - loss: 1023.5757 - val_loss: 477.6256\n",
            "Epoch 45/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1023.1369 - val_loss: 477.4909\n",
            "Epoch 46/101\n",
            "3/3 [==============================] - 3s 805ms/step - loss: 1022.6609 - val_loss: 477.2911\n",
            "Epoch 47/101\n",
            "3/3 [==============================] - 3s 802ms/step - loss: 1022.1606 - val_loss: 477.2352\n",
            "Epoch 48/101\n",
            "3/3 [==============================] - 3s 802ms/step - loss: 1021.6698 - val_loss: 477.2622\n",
            "Epoch 49/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1021.2264 - val_loss: 477.2597\n",
            "Epoch 50/101\n",
            "3/3 [==============================] - 3s 804ms/step - loss: 1020.7554 - val_loss: 477.2295\n",
            "Epoch 51/101\n",
            "3/3 [==============================] - 3s 797ms/step - loss: 1020.3281 - val_loss: 477.1957\n",
            "Epoch 52/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1019.9027 - val_loss: 477.1800\n",
            "Epoch 53/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1019.4943 - val_loss: 477.1691\n",
            "Epoch 54/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1019.1067 - val_loss: 477.1630\n",
            "Epoch 55/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1018.7310 - val_loss: 477.1543\n",
            "Epoch 56/101\n",
            "3/3 [==============================] - 3s 803ms/step - loss: 1018.3702 - val_loss: 477.1407\n",
            "Epoch 57/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1018.0229 - val_loss: 477.1232\n",
            "Epoch 58/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1017.6869 - val_loss: 477.0958\n",
            "Epoch 59/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1017.3573 - val_loss: 477.0737\n",
            "Epoch 60/101\n",
            "3/3 [==============================] - 3s 802ms/step - loss: 1017.0363 - val_loss: 477.0643\n",
            "Epoch 61/101\n",
            "3/3 [==============================] - 3s 802ms/step - loss: 1016.7238 - val_loss: 477.0620\n",
            "Epoch 62/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1016.4205 - val_loss: 477.0494\n",
            "Epoch 63/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1016.1216 - val_loss: 477.0375\n",
            "Epoch 64/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1015.8305 - val_loss: 477.0314\n",
            "Epoch 65/101\n",
            "3/3 [==============================] - 3s 802ms/step - loss: 1015.5444 - val_loss: 477.0155\n",
            "Epoch 66/101\n",
            "3/3 [==============================] - 3s 825ms/step - loss: 1015.2608 - val_loss: 476.9903\n",
            "Epoch 67/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1014.9788 - val_loss: 476.9675\n",
            "Epoch 68/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1014.6984 - val_loss: 476.9419\n",
            "Epoch 69/101\n",
            "3/3 [==============================] - 3s 798ms/step - loss: 1014.4244 - val_loss: 476.9185\n",
            "Epoch 70/101\n",
            "3/3 [==============================] - 3s 798ms/step - loss: 1014.1700 - val_loss: 476.9033\n",
            "Epoch 71/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1013.9224 - val_loss: 476.8831\n",
            "Epoch 72/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1013.6586 - val_loss: 476.8734\n",
            "Epoch 73/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1013.4006 - val_loss: 476.8665\n",
            "Epoch 74/101\n",
            "3/3 [==============================] - 3s 796ms/step - loss: 1013.1541 - val_loss: 476.8623\n",
            "Epoch 75/101\n",
            "3/3 [==============================] - 3s 795ms/step - loss: 1012.9113 - val_loss: 476.8588\n",
            "Epoch 76/101\n",
            "3/3 [==============================] - 3s 795ms/step - loss: 1012.6693 - val_loss: 476.8549\n",
            "Epoch 77/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1012.4194 - val_loss: 476.8434\n",
            "Epoch 78/101\n",
            "3/3 [==============================] - 3s 797ms/step - loss: 1012.1346 - val_loss: 476.8379\n",
            "Epoch 79/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1011.8066 - val_loss: 476.8636\n",
            "Epoch 80/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1011.5031 - val_loss: 476.8500\n",
            "Epoch 81/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1011.2238 - val_loss: 476.7938\n",
            "Epoch 82/101\n",
            "3/3 [==============================] - 3s 798ms/step - loss: 1010.9520 - val_loss: 476.8205\n",
            "Epoch 83/101\n",
            "3/3 [==============================] - 3s 798ms/step - loss: 1010.6614 - val_loss: 476.8585\n",
            "Epoch 84/101\n",
            "3/3 [==============================] - 3s 795ms/step - loss: 1010.3984 - val_loss: 476.8437\n",
            "Epoch 85/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1010.1685 - val_loss: 476.8103\n",
            "Epoch 86/101\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 1009.9069 - val_loss: 476.8474\n",
            "Epoch 87/101\n",
            "3/3 [==============================] - 3s 798ms/step - loss: 1009.6816 - val_loss: 476.8835\n",
            "Epoch 88/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1009.4636 - val_loss: 476.8599\n",
            "Epoch 89/101\n",
            "3/3 [==============================] - 3s 802ms/step - loss: 1009.2463 - val_loss: 476.8352\n",
            "Epoch 90/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1009.0391 - val_loss: 476.8463\n",
            "Epoch 91/101\n",
            "3/3 [==============================] - 3s 830ms/step - loss: 1008.8403 - val_loss: 476.8638\n",
            "Epoch 92/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1008.6379 - val_loss: 476.8673\n",
            "Epoch 93/101\n",
            "3/3 [==============================] - 3s 796ms/step - loss: 1008.4405 - val_loss: 476.8729\n",
            "Epoch 94/101\n",
            "3/3 [==============================] - 3s 797ms/step - loss: 1008.2488 - val_loss: 476.8857\n",
            "Epoch 95/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1008.0595 - val_loss: 476.8813\n",
            "Epoch 96/101\n",
            "3/3 [==============================] - 3s 798ms/step - loss: 1007.8748 - val_loss: 476.8723\n",
            "Epoch 97/101\n",
            "3/3 [==============================] - 3s 797ms/step - loss: 1007.6947 - val_loss: 476.8824\n",
            "Epoch 98/101\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 1007.5201 - val_loss: 476.8961\n",
            "Epoch 99/101\n",
            "3/3 [==============================] - 3s 799ms/step - loss: 1007.3481 - val_loss: 476.8935\n",
            "Epoch 100/101\n",
            "3/3 [==============================] - 3s 797ms/step - loss: 1007.1779 - val_loss: 476.8840\n",
            "Epoch 101/101\n",
            "3/3 [==============================] - 3s 797ms/step - loss: 1007.0112 - val_loss: 476.8929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(model.layers)):\n",
        "  model.layers[i].trainable = True"
      ],
      "metadata": {
        "id": "d92PoOSIEwXR"
      },
      "id": "d92PoOSIEwXR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path): \n",
        "  image = load_img(image_path,target_size=(448,448)) \n",
        "  image = img_to_array(image) \n",
        "  image = image/255 \n",
        "  return np.expand_dims(image,0)"
      ],
      "metadata": {
        "id": "I5-AQjZdHUii"
      },
      "id": "I5-AQjZdHUii",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoding Prediction"
      ],
      "metadata": {
        "id": "XZjA6ZjlHBpj"
      },
      "id": "XZjA6ZjlHBpj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc514d98",
      "metadata": {
        "id": "cc514d98"
      },
      "outputs": [],
      "source": [
        "def decode_pred(y_matrix,thresh=.5):\n",
        "    i_s = []\n",
        "    j_s = []\n",
        "    classes = []\n",
        "    bboxes = []\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            if y_matrix[0][i][j][4] > thresh:\n",
        "                i_s.append(i)\n",
        "                j_s.append(j)\n",
        "    for idx in range(len(i_s)):\n",
        "        i = i_s[idx]\n",
        "        j = j_s[idx]\n",
        "        cls = np.argmax(y_matrix[0][i,j,:4])\n",
        "        classes.append(cls)\n",
        "        box = y_matrix[0][i,j,6:10]\n",
        "        bboxes.append(box)\n",
        "    return classes,bboxes"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}